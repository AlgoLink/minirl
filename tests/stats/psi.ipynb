{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-19 13:29:21 [info     ] APIs of mlopskit               model_name=feature_store model_version=1 ops_type=cache\n",
      "2023-06-19 13:29:21 [info     ] The list of all versions for the current model is \u001b[42;1m[1, 2]\u001b[0m.\n",
      "2023-06-19 13:29:21 [warning  ] The version 1 is out of date. You should consider upgrading to version `v2`.\n",
      "2023-06-19 13:29:21 [info     ] Usage of mlopskit-cache        Params=\u001b[36;1m{'db_type': 'rlite/redis/sfdb/diskcache, default:rlite', 'return_type': 'dblink/dbobj, default: dbobj', 'db_name': 'default: rlite_model.cache'}\u001b[0m\n",
      "2023-06-19 13:29:21 [info     ] APIs of mlopskit               model_name=feature_store model_version=1 ops_type=cache\n",
      "2023-06-19 13:29:21 [info     ] The list of all versions for the current model is \u001b[42;1m[1, 2]\u001b[0m.\n",
      "2023-06-19 13:29:21 [warning  ] The version 1 is out of date. You should consider upgrading to version `v2`.\n",
      "2023-06-19 13:29:21 [info     ] Usage of mlopskit-cache        Params=\u001b[36;1m{'db_type': 'rlite/redis/sfdb/diskcache, default:rlite', 'return_type': 'dblink/dbobj, default: dbobj', 'db_name': 'default: rlite_model.cache'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from mlopskit import make\n",
    "\n",
    "model_db = make(\n",
    "            \"cache/feature_store-v1\", db_name=\"psi.db\"\n",
    "        )\n",
    "\n",
    "\n",
    "his_db = make(\n",
    "            \"cache/feature_store-v1\", db_name=\"psi_his.db\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minirl.stats.psi import OnlinePSI\n",
    "\n",
    "test=OnlinePSI(model_db=model_db,his_db=his_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "import copy\n",
    "\n",
    "SHA_TZ = timezone(\n",
    "    timedelta(hours=8),\n",
    "    name=\"Asia/Shanghai\",\n",
    ")\n",
    "\n",
    "\n",
    "def get_bj_day():\n",
    "    utc_now = datetime.utcnow().replace(tzinfo=timezone.utc) - timedelta(hours=11)\n",
    "    beijing_now = utc_now.astimezone(SHA_TZ)\n",
    "    _bj = beijing_now.strftime(\"%Y-%m-%d\")  # 结果显示：'2017-10-07'\n",
    "\n",
    "    return _bj\n",
    "\n",
    "\n",
    "def get_bj_date():\n",
    "    utc_now = datetime.utcnow().replace(tzinfo=timezone.utc) - timedelta(hours=11)\n",
    "    beijing_now = utc_now.astimezone(SHA_TZ)\n",
    "    _bj = beijing_now\n",
    "\n",
    "    return _bj\n",
    "\n",
    "\n",
    "def get_week_day():\n",
    "    utc_now = datetime.utcnow().replace(tzinfo=timezone.utc) - timedelta(hours=11)\n",
    "    beijing_now = utc_now.astimezone(SHA_TZ)\n",
    "\n",
    "    return beijing_now.weekday()\n",
    "\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype=\"bins\", buckets=10, axis=0):\n",
    "    \"\"\"Calculate the PSI (population stability index) across all variables\n",
    "\n",
    "    Args:\n",
    "       expected: numpy matrix of original values\n",
    "       actual: numpy matrix of new values, same size as expected\n",
    "       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
    "       buckets: number of quantiles to use in bucketing variables\n",
    "       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
    "\n",
    "    Returns:\n",
    "       psi_values: ndarray of psi values for each variable\n",
    "\n",
    "    Author:\n",
    "       Matthew Burke\n",
    "       github.com/mwburke\n",
    "       worksofchart.com\n",
    "    \"\"\"\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        \"\"\"Calculate the PSI for a single variable\n",
    "\n",
    "        Args:\n",
    "           expected_array: numpy array of original values\n",
    "           actual_array: numpy array of new values, same size as expected\n",
    "           buckets: number of percentile ranges to bucket the values into\n",
    "\n",
    "        Returns:\n",
    "           psi_value: calculated PSI value\n",
    "        \"\"\"\n",
    "\n",
    "        def scale_range(input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "\n",
    "        if buckettype == \"bins\":\n",
    "            breakpoints = scale_range(\n",
    "                breakpoints, np.min(expected_array), np.max(expected_array)\n",
    "            )\n",
    "        elif buckettype == \"quantiles\":\n",
    "            breakpoints = np.stack(\n",
    "                [np.percentile(expected_array, b) for b in breakpoints]\n",
    "            )\n",
    "\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(\n",
    "            expected_array\n",
    "        )\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            \"\"\"Calculate the actual PSI value from comparing the values.\n",
    "            Update the actual value to a very small number if equal to zero\n",
    "            \"\"\"\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return value\n",
    "\n",
    "        sum_gen = (\n",
    "            sub_psi(expected_percents[i], actual_percents[i])\n",
    "            for i in range(0, len(expected_percents))\n",
    "        )\n",
    "        psi_value = np.sum(np.fromiter(sum_gen, dtype=float))\n",
    "\n",
    "        return psi_value\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        if len(psi_values) == 1:\n",
    "            psi_values = psi(expected, actual, buckets)\n",
    "        elif axis == 0:\n",
    "            psi_values[i] = psi(expected[:, i], actual[:, i], buckets)\n",
    "        elif axis == 1:\n",
    "            psi_values[i] = psi(expected[i, :], actual[i, :], buckets)\n",
    "\n",
    "    return psi_values\n",
    "\n",
    "\n",
    "class OnlinePSI:\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_size=30,\n",
    "        stat_size=7,\n",
    "        model_db=None,\n",
    "        his_db=None,\n",
    "        buckettype=\"bins\",\n",
    "        buckets=10,\n",
    "    ) -> None:\n",
    "        self.window_size = window_size\n",
    "        self.stat_size = stat_size\n",
    "        self._model_db = model_db\n",
    "        self._his_db = his_db\n",
    "        self.buckettype = buckettype\n",
    "        self.buckets = buckets\n",
    "\n",
    "        self._init_model()\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.window = collections.deque(maxlen=self.window_size)\n",
    "        today = get_bj_day()\n",
    "        self.psi = {\"date\": today, \"psi\": -1}\n",
    "\n",
    "    def get_defu_psi(self):\n",
    "        today = get_bj_day()\n",
    "        return {\"date\": today, \"psi\": -1}\n",
    "\n",
    "    def act(self, model_id, feat_list=[], feat_type=\"spin\"):\n",
    "        new_model_id = f\"{model_id}:{feat_type}\"\n",
    "        model_key = self.get_model_key(new_model_id)\n",
    "\n",
    "        if len(feat_list) != 7:\n",
    "            return self.get_model(model_key)\n",
    "        last7_dates = self.get_dates(start=7, step=7)\n",
    "        # list 和 dates 一一对应\n",
    "        lst = feat_list\n",
    "        data_dict = dict(zip(last7_dates, lst))\n",
    "\n",
    "        last14_dates = self.get_dates(start=14, step=7)\n",
    "        old_data_key = self.get_data_key(new_model_id)\n",
    "        old_data = self._his_db.get(old_data_key)\n",
    "        tmp_data_key = self.get_data_key(f\"{new_model_id}:tmp\")\n",
    "        tmp_data = self._his_db.get(tmp_data_key)\n",
    "        if old_data is None:\n",
    "            old_expected_data_dict = data_dict\n",
    "            self._his_db.set(old_data_key, pickle.dumps(old_expected_data_dict))\n",
    "            self._his_db.set(tmp_data_key, pickle.dumps(old_expected_data_dict))\n",
    " \n",
    "            return self.get_defu_psi()\n",
    "        else:\n",
    "            old_expected_data_dict = pickle.loads(old_data)\n",
    "            if tmp_data is None:\n",
    "                tmp_data = {}\n",
    "            else:\n",
    "                tmp_data = pickle.loads(tmp_data)\n",
    "\n",
    "            expected_data_dict = {}\n",
    "            for d in last14_dates:\n",
    "                d1 = old_expected_data_dict.get(d)\n",
    "                d2 = tmp_data.get(d)\n",
    "                if d1 is not None:\n",
    "                    expected_data_dict[d] = d1\n",
    "                else:\n",
    "                    if d2 is not None:\n",
    "                        expected_data_dict[d] = d2\n",
    "                    else:\n",
    "                        expected_data_dict[d] = 0\n",
    "            expected_data_list = list(expected_data_dict.values())\n",
    "            if sum(expected_data_list)==0:\n",
    "                expected_data_list[-1]=0.00001\n",
    "            expected_data_array = np.array(expected_data_list)\n",
    "            actual_array = np.array(feat_list)\n",
    "\n",
    "            new_psi = calculate_psi(\n",
    "                expected_data_array,\n",
    "                actual_array,\n",
    "                buckettype=self.buckettype,\n",
    "                buckets=self.buckets,\n",
    "                axis=0,\n",
    "            )\n",
    "\n",
    "            self._his_db.set(tmp_data_key, pickle.dumps(data_dict))\n",
    "            \n",
    "            self._his_db.set(old_data_key, pickle.dumps(expected_data_dict))\n",
    "            model = {\"date\": get_bj_day(), \"psi\": new_psi}\n",
    "            self.save_model(model_key, model)\n",
    "\n",
    "            return new_psi\n",
    "\n",
    "    def learn(self):\n",
    "        pass\n",
    "\n",
    "    def get_data_key(self, model_id):\n",
    "        return f\"{model_id}:his\"\n",
    "\n",
    "    def get_model_key(self, model_id):\n",
    "        return f\"{model_id}:psi\"\n",
    "\n",
    "    def load_model(self, model_id):\n",
    "        model_key = self.get_model_key(model_id)\n",
    "        _model = self._model_db.get(model_key)\n",
    "        if _model is None:\n",
    "            today = get_bj_day()\n",
    "            model = {\"date\": today, \"psi\": -1}\n",
    "        else:\n",
    "            model = pickle.loads(_model)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def save_model(self, model_id, model):\n",
    "        model_key = self.get_model_key(model_id)\n",
    "        self._model_db.set(model_key, pickle.dumps(model))\n",
    "\n",
    "    def get_model(self, model_id):\n",
    "        return self.load_model(model_id)\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.psi = copy.deepcopy(model)\n",
    "\n",
    "    def get_dates(self, start=14, step=7):\n",
    "        end_date = get_bj_date()\n",
    "        start_date = end_date - timedelta(days=start)\n",
    "\n",
    "        # 生成日期列表\n",
    "        dates = []\n",
    "        for i in range(step):\n",
    "            date = start_date + timedelta(days=i)\n",
    "            dates.append(date.strftime(\"%Y-%m-%d\"))\n",
    "        return dates\n",
    "\n",
    "    def get_tmp_data(self,model_id,feat_type=\"spin\"):\n",
    "        new_model_id = f\"{model_id}:{feat_type}\"\n",
    "        tmp_data_key = self.get_data_key(f\"{new_model_id}:tmp\")\n",
    "\n",
    "        tmp_data = self._his_db.get(tmp_data_key)\n",
    "        if tmp_data is None:\n",
    "            return {}\n",
    "        else:\n",
    "            return pickle.loads(tmp_data)\n",
    "\n",
    "    def get_base_data(self,model_id,feat_type=\"spin\"):\n",
    "        new_model_id = f\"{model_id}:{feat_type}\"\n",
    "        old_data_key = self.get_data_key(new_model_id)\n",
    "        data = self._his_db.get(old_data_key)\n",
    "        if data is None:\n",
    "            return {}\n",
    "        else:\n",
    "            return pickle.loads(data)\n",
    "\n",
    "test=OnlinePSI(model_db=model_db,his_db=his_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1528964768544505"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.act('t2',feat_list=[100,1,0,0,0,0,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.get_base_data(\"t2\").values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.664827753776752"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.act('t2',feat_list=[100,1,0,90,90,0,10000011])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2023-06-05': 0,\n",
       " '2023-06-06': 0,\n",
       " '2023-06-07': 0,\n",
       " '2023-06-08': 0,\n",
       " '2023-06-09': 0,\n",
       " '2023-06-10': 0,\n",
       " '2023-06-11': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.get_base_data(\"t2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2023-06-12': 100,\n",
       " '2023-06-13': 1,\n",
       " '2023-06-14': 0,\n",
       " '2023-06-15': 0,\n",
       " '2023-06-16': 0,\n",
       " '2023-06-17': 0,\n",
       " '2023-06-18': 11}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.get_tmp_data(\"t2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2023-06-19',\n",
       " 'psi': 1.664827753776752,\n",
       " 'old_date': '2023-06-19',\n",
       " 'old_psi': -1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.get_model(\"t2:spin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f06f4baf162c1bba868b3ed890ca059fd0c13f705dc9d48413e36c65b86dd60d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

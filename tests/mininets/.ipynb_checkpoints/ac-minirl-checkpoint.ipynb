{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3121d14-6585-4335-93dd-1a503ca07d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.py\n"
     ]
    }
   ],
   "source": [
    "%%file config.py\n",
    "import numpy as np\n",
    "import minirl.neural_nets.nn.init\n",
    "import minirl.neural_nets.nn.optim\n",
    "from minirl.neural_nets.nn.init import custom\n",
    "from minirl.neural_nets.nn.optim import rmsprop\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self, args):\n",
    "        # Default training settings\n",
    "        self.init_func = custom\n",
    "        self.init_config = {\n",
    "            'function': lambda shape: np.random.randn(shape[0], shape[1]) / np.sqrt(shape[1])\n",
    "        }\n",
    "        self.learning_rate = 1e-3\n",
    "        self.update_rule = rmsprop\n",
    "        self.grad_clip = True\n",
    "        self.clip_magnitude = 40.0\n",
    "\n",
    "        # Default model settings\n",
    "        self.hidden_size = 200\n",
    "        self.gamma = 0.99\n",
    "        self.lambda_ = 1.0\n",
    "        self.vf_wt = 0.5        # Weight of value function term in the loss\n",
    "        self.entropy_wt = 0.01  # Weight of entropy term in the loss\n",
    "\n",
    "        # Override defaults with values from `args`.\n",
    "        for arg in self.__dict__:\n",
    "            if arg in args.__dict__:\n",
    "                self.__setattr__(arg, args.__dict__[arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcbcf755-4859-48ce-98eb-d16dc1651b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%file model.py\n",
    "from itertools import chain\n",
    "import numpy\n",
    "import scipy.signal\n",
    "\n",
    "import minirl.neural_nets.nn.init\n",
    "import minirl.neural_nets.core as core\n",
    "import minirl.neural_nets.numpy as np\n",
    "from minirl.neural_nets.nn.model import ModelBase\n",
    "import minirl.neural_nets.numpy as np\n",
    "from minirl.neural_nets.nn.init import constant\n",
    "\n",
    "class Agent(ModelBase):\n",
    "    def __init__(self, input_size, act_space, config):\n",
    "        super(Agent, self).__init__()\n",
    "        self.ctx = config.ctx\n",
    "        self.act_space = act_space\n",
    "        self.config = config\n",
    "        self.add_param('fc1', (config.hidden_size, input_size))\n",
    "        self.add_param('policy_fc_last', (act_space, config.hidden_size))\n",
    "        self.add_param('vf_fc_last', (1, config.hidden_size))\n",
    "        self.add_param('vf_fc_last_bias', (1,))\n",
    "\n",
    "        self._init_params()\n",
    "\n",
    "        self.optim_configs = {}\n",
    "        for p in self.param_configs:\n",
    "            self.optim_configs[p] = {'learning_rate': self.config.learning_rate}\n",
    "\n",
    "    def forward(self, X):\n",
    "        a = np.dot(self.params['fc1'], X.T)\n",
    "        h = np.maximum(0, a)\n",
    "        logits = np.dot(h.T, self.params['policy_fc_last'].T)\n",
    "        ps = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "        ps /= np.sum(ps, axis=1, keepdims=True)\n",
    "        vs = np.dot(h.T, self.params['vf_fc_last'].T) + self.params['vf_fc_last_bias']\n",
    "        return ps, vs\n",
    "\n",
    "    def loss(self, ps, as_, vs, rs, advs):\n",
    "        ps = np.maximum(1.0e-5, np.minimum(1.0 - 1e-5, ps))\n",
    "        policy_grad_loss = -np.sum(np.log(ps) * as_ * advs)\n",
    "        vf_loss = 0.5*np.sum((vs - rs)**2)\n",
    "        entropy = -np.sum(ps*np.log(ps))\n",
    "        loss_ = policy_grad_loss + self.config.vf_wt*vf_loss - self.config.entropy_wt*entropy\n",
    "        return loss_\n",
    "\n",
    "    def act(self, ps):\n",
    "        us = numpy.random.uniform(size=ps.shape[0])[:, np.newaxis]\n",
    "        as_ = (numpy.cumsum(ps.asnumpy(), axis=1) > us).argmax(axis=1)\n",
    "        return as_\n",
    "\n",
    "    def train_step(self, env_xs, env_as, env_rs, env_vs):\n",
    "        # Stack all the observations and actions.\n",
    "        xs = np.vstack(list(chain.from_iterable(env_xs)))\n",
    "        as_ = numpy.array(list(chain.from_iterable(env_as)))[:, np.newaxis]\n",
    "        # One-hot encode the actions.\n",
    "        buf = numpy.zeros([xs.shape[0], self.act_space])\n",
    "        as_ = np.onehot_encode(np.array(as_.ravel(), self.ctx), buf).asnumpy()\n",
    "\n",
    "        # Compute discounted rewards and advantages.\n",
    "        drs, advs = [], []\n",
    "        gamma, lambda_ = self.config.gamma, self.config.lambda_\n",
    "        for i in range(len(env_vs)):\n",
    "            # Compute discounted rewards with a 'bootstrapped' final value.\n",
    "            rs_bootstrap = [] if env_rs[i] == [] else env_rs[i] + [env_vs[i][-1]]\n",
    "            drs.extend(self._discount(rs_bootstrap, gamma)[:-1])\n",
    "\n",
    "            # Compute advantages using Generalized Advantage Estimation;\n",
    "            # see eqn. (16) of [Schulman 2016].\n",
    "            delta_t = env_rs[i] + gamma*numpy.array(env_vs[i][1:]) - numpy.array(env_vs[i][:-1])\n",
    "            advs.extend(self._discount(delta_t, gamma * lambda_))\n",
    "\n",
    "        drs = numpy.array(drs)[:, np.newaxis]\n",
    "        advs = numpy.array(advs)[:, np.newaxis]\n",
    "\n",
    "        def loss_func(*params):\n",
    "            ps, vs = self.forward(xs)\n",
    "            loss_ = self.loss(ps, as_, vs, drs, advs)\n",
    "            return loss_\n",
    "\n",
    "        grads = self._forward_backward(loss_func)\n",
    "        self._update_params(grads)\n",
    "\n",
    "    def _discount(self, x, gamma):\n",
    "        return scipy.signal.lfilter([1], [1, -gamma], x[::-1], axis=0)[::-1]\n",
    "\n",
    "    def _forward_backward(self, loss_func):\n",
    "        param_arrays = list(self.params.values())\n",
    "        param_keys = list(self.params.keys())\n",
    "        grad_and_loss_func = core.grad_and_loss(loss_func, argnum=range(len(param_arrays)))\n",
    "        grad_arrays, loss = grad_and_loss_func(*param_arrays)\n",
    "        grads = dict(zip(param_keys, grad_arrays))\n",
    "        if self.config.grad_clip:\n",
    "            for k, v in grads.iteritems():\n",
    "                grads[k] = numpy.clip(v, -self.config.clip_magnitude, self.config.clip_magnitude)\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def _update_params(self, grads):\n",
    "        for p, w in self.params.iteritems():\n",
    "            dw = grads[p]\n",
    "            config = self.optim_configs[p]\n",
    "            next_w, next_config = self.config.update_rule(w, dw, config)\n",
    "            self.params[p] = next_w\n",
    "            self.optim_configs[p] = next_config\n",
    "\n",
    "    def _init_params(self):\n",
    "        for name, config in self.param_configs.items():\n",
    "            init_func = constant if name.endswith('bias') else self.config.init_func\n",
    "            self.params[name] = init_func(config['shape'], self.config.init_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9e2f5-bbeb-49af-93ec-34282d54ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42373290-d026-46e2-b12e-c81f07f65d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from itertools import count\n",
    "from minirl import uniAgent\n",
    "log_interval=100\n",
    "render_interval = -1\n",
    "#env = gym.make(\"LunarLander-v2\")\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "ob_n = env.observation_space.shape[0]\n",
    "ac_n = env.action_space.n\n",
    "agent = uniAgent(ob_n,ac_n,p_alpha=0.001,v_alpha=0.001,algo=\"ppo\",clip=0.2,capacity=10000,batch_size=1000)\n",
    "def main():\n",
    "    \"\"\"Run REINFORCE algorithm to train on the environment\"\"\"\n",
    "    avg_reward = []\n",
    "    for i_episode in count(1):\n",
    "        ep_reward = 0\n",
    "        obs,_ = env.reset()\n",
    "        for t in range(10000):  # Don't infinite loop while learning\n",
    "            #sprint(obs)\n",
    "            action,p = agent.act(obs)\n",
    "            next_obs, reward, done, _,_ = env.step(action)\n",
    "            ep_reward += reward\n",
    "            #reinforce.rewards.append(reward)\n",
    "\n",
    "            \n",
    "    \n",
    "            if render_interval != -1 and i_episode % render_interval == 0:\n",
    "                env.render()\n",
    "\n",
    "            agent.learn(obs, reward, next_obs)\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "            obs=next_obs\n",
    "        #reinforce.finish_episode()\n",
    "\n",
    "        if i_episode % log_interval == 0:\n",
    "            print(\"Ave reward: {}\".format(sum(avg_reward)/len(avg_reward)))\n",
    "            avg_reward = []\n",
    "\n",
    "        else:\n",
    "            avg_reward.append(ep_reward)\n",
    "            \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde868ce-946c-4b92-94e2-c25b6a45c4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.bool_' object has no attribute 'mark_for_bp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m x\n\u001b[1;32m      9\u001b[0m foo_grad \u001b[38;5;241m=\u001b[39m grad(foo)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43mfoo_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# should print 1.0\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m (foo_grad(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# should print 2.0\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/minirl/neural_nets/core.py:87\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(grad_with_loss_func)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_with_loss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/minirl/neural_nets/core.py:42\u001b[0m, in \u001b[0;36mgrad_and_loss.<locals>.wrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnums:\n\u001b[1;32m     41\u001b[0m     arrays[i]\u001b[38;5;241m.\u001b[39mmark_for_bp(current_tape)\n\u001b[0;32m---> 42\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m current_tape\u001b[38;5;241m.\u001b[39mstop_recording()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Wrap result value.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# TODO(minjie): Also wait for result value to be finished. This prevents\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# backward propagation to be run in parallel with forward propagation.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# The main reason this is not allowed right now is due to the potential\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# large memory consumption. This should be fixed by a more systemetic\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# way in the future.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mfoo\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfoo\u001b[39m(x):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/minirl/neural_nets/array.py:87\u001b[0m, in \u001b[0;36mValue.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mValue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreater_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/minirl/neural_nets/primitive.py:135\u001b[0m, in \u001b[0;36mPrimitive.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrap args for `call` method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/minirl/neural_nets/primitive.py:267\u001b[0m, in \u001b[0;36mPrimitive.call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m--> 267\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmark_for_bp\u001b[49m(current_tape)  \u001b[38;5;66;03m# pylint: disable= no-member\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Record partial derivative paths, only for `array.Value` type values.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# If no gradient function is defined, also omit it.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m visited_arg_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.bool_' object has no attribute 'mark_for_bp'"
     ]
    }
   ],
   "source": [
    "\n",
    "from minirl.neural_nets.core import grad\n",
    "\n",
    "def foo(x):\n",
    "    if x >= 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 2 * x\n",
    "\n",
    "foo_grad = grad(foo)\n",
    "print (foo_grad(3))  # should print 1.0\n",
    "print (foo_grad(-1)) # should print 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de0300-e266-4498-baa7-341275998306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minpy\n",
    "minpy.set_global_policy('only_numpy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
